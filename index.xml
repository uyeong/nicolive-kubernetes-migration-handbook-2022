<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>니코니코 생방송 웹 프런트엔드의 쿠버네티스 마이그레이션 핸드북 2022 on 니코니코 생방송 웹 프런트엔드의 쿠버네티스 이전 핸드북 2022</title><link>https://uyeong.github.io/nicolive-kubernetes-migration-handbook-2022/</link><description>Recent content in 니코니코 생방송 웹 프런트엔드의 쿠버네티스 마이그레이션 핸드북 2022 on 니코니코 생방송 웹 프런트엔드의 쿠버네티스 이전 핸드북 2022</description><generator>Hugo -- gohugo.io</generator><language>kr-KR</language><atom:link href="https://uyeong.github.io/nicolive-kubernetes-migration-handbook-2022/index.xml" rel="self" type="application/rss+xml"/><item><title>이전 전 / 중 / 후의 네트워크 설계</title><link>https://uyeong.github.io/nicolive-kubernetes-migration-handbook-2022/docs/network/architecture/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://uyeong.github.io/nicolive-kubernetes-migration-handbook-2022/docs/network/architecture/</guid><description>이전 전 / 중 / 후의 네트워크 설계 # 이전 전의 네트워크 구성 # 위 그림은 이전 전 즉, 도커 스웜 위주의 네트워크 구성도다.
트래픽을 최상위의 로드밸런서에서 받은 뒤 아파치(혹은 엔진엑스, OpenResty 등)와 같은 L7 로드밸런서에 전달한 후 도커 스웜의 클러스터에 도달한다. 이어서 컨테이너 네트워크에 접속 되고 최종적으로 웹 애플리케이션이 응답을 반환하게 된다.
이전 중의 네트워크 구성 # 위 그림은 도커 스웜에서 쿠버네티스로 이전하는 과정 중 활용한 네트워크 구성이다.</description></item><item><title>쿠버네티스의 매니페스트 관리</title><link>https://uyeong.github.io/nicolive-kubernetes-migration-handbook-2022/docs/manifest/manifest-management/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://uyeong.github.io/nicolive-kubernetes-migration-handbook-2022/docs/manifest/manifest-management/</guid><description>쿠버네티스의 매니페스트 관리 # 이번 장에서는 매니페스트 관리를 어떻게 하고 있는지 소개한다. 결론부터 말하면 우리는 쿠버네티스에서 이용할 매니페스트를 생성해 주는 제너레이터를 타입스크립트로 구축했다.
어떻게 구축하여 운용하고 있는지 설명한다.
이전 후 각 컴포넌트의 파일 수로 살펴보는 규모 # 도입 부분에서 다뤘던 자료를 다시금 언급. 프런트엔드와 관련한 마이크로서비스의 매니페스트는 다음과 같은 규모로 존재한다. 이는 간단히 관리할 수 없는 컴포넌트 수이며 앞으로도 늘어날 전망이다.
컴포넌트 파일 수 v1/Deployment 20 v1/Service 60 v1/Config Map 15 batch/v1/Job 15 argoproj.</description></item><item><title>타입스크립트로 쿠버네티스의 매니페스트를 작성한다</title><link>https://uyeong.github.io/nicolive-kubernetes-migration-handbook-2022/docs/manifest/kubernetes-manifest-written-by-typescript/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://uyeong.github.io/nicolive-kubernetes-migration-handbook-2022/docs/manifest/kubernetes-manifest-written-by-typescript/</guid><description>타입스크립트로 쿠버네티스의 매니페스트를 작성한다 # 이번 절에서는 기본적인 작성 방법을 소개한다.
기본적인 작성 방법 # 아래 코드는 타입스크립트로 작성한 스크립트(노드에서 동작하는)의 예다. 이를 ts-node 등으로 실행하면 deployment.yml가 출력되며 kubectl apply -f deployment.yml하여 쿠버네티스 상에 팟을 기동 시킬 수 있다.
import * as fs from &amp;#34;fs&amp;#34;; import * as yaml from &amp;#34;js-yaml&amp;#34;; import type { Schemas } from &amp;#34;@himenon/kubernetes-typescript-openapi/v1.22.3&amp;#34;; const podTemplateSpec: Schemas.io$k8s$api$core$v1$PodTemplateSpec = { metadata: { labels: { app: &amp;#34;nginx&amp;#34;, }, }, spec: { containers: [ { name: &amp;#34;nginx&amp;#34;, image: &amp;#34;nginx:1.</description></item><item><title>TypeScriptでManifestを生成するGeneratorのアーキテクチャ</title><link>https://uyeong.github.io/nicolive-kubernetes-migration-handbook-2022/docs/manifest/kubernetes-manifest-generator-architecture/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://uyeong.github.io/nicolive-kubernetes-migration-handbook-2022/docs/manifest/kubernetes-manifest-generator-architecture/</guid><description>TypeScriptでManifestを生成するGeneratorのアーキテクチャ # アーキテクチャが解決すること # そもそも Generator そのものが解決することは manifest をドキュメントの乖離を防ぎ、YAMLの記法のぶれなどを防ぐことです。 アーキテクチャが解決しなければいけないことは、具体的には次のようなことが挙げられます。
マニフェスト自体のスケーラビリティを確保する 実際に運用する際に必要最小限の変更だけで Manifest を更新できる ≒ 宣言的な変更で済むようにする マイクロサービス単位で設定の変更ができる（CPU/MEM/replicas など） 管理しているマイクロサービス全体のリソース量、変更時の増減が把握できる Manifest ファイルの命名規則、出力先のディレクトリ・ファイルツリーなどを意識しなくても良い Generator 自体の保守性を高める これらを表現するためのアーキテクチャはStatic Site GeneratorやYeoman、Cookiecutter、Rails Scaffoldなどたくさん事例があります。 これらの基本的な骨格をKubernetesのManifest Generatorとして応用し次のようなアーキテクチャが設計しました。
それぞれの役割を紹介します。
名称 役割 User Config バージョン変更など最小限の変更を与えるファイル Kubernetes TypeDefinition TypeScriptの型定義 MicroService Template マイクロサービスの種類に応じたテンプレート Definition Namespace名やPort番号、Gatewayの Host 名などの不動値の定義 Resource ParameterとMicroService Templateを Kubernetes のリソースコンポーネント単位で結合する Factory Resourceをどのファイル名でどのグループで出力するか定義する Writer Factory から与えられた情報から Kubernetes の Manifest や、CPU Requests などのレポートを生成する 具体的な実装例 # 実装サンプルを以下のリポジトリに用意しました。nodejsとpnpmを利用したサンプルとなっています。 Docker Swarmを利用すればArgo Rollouts + Istioがデプロイできるところまで確認しています。</description></item><item><title>Argo CDの利用</title><link>https://uyeong.github.io/nicolive-kubernetes-migration-handbook-2022/docs/ci/argo-cd/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://uyeong.github.io/nicolive-kubernetes-migration-handbook-2022/docs/ci/argo-cd/</guid><description>Argo CD # ニコニコ生放送のフロントエンドではContinuous Delivery(以降CD)ツールとしてArgo CDとArgo Rolloutsを利用しています。 ここではその運用と設計について紹介します。
注意書き
argoproj.io/v1alpha1/Applicationのことを「ArgoCDのApplication」と表記します。 他チームとの棲み分け # Argo CDはフロントエンドのチームだけではなく、他のチームが管理するものも存在しています。 したがってチーム横断で管理している部分が存在するとレビューコストが上がるため、App of Apps Patternsを利用して管理するArgocd Applicationをフロントエンドチームのnamespaceで分離しました。
具体的にはapp of appsを2段階で利用して次の図ように分離しています。
図中のRoot ArgoCD Appsは他チームと干渉する部分になっています。 ここに、フロントエンドチームが管理するArgoCD Appsを配置します
apiVersion: argoproj.io/v1alpha1 kind: Application metadata: name: frontend-apps finalizers: - resources-finalizer.argocd.argoproj.io spec: project: default source: targetRevision: master repoURL: # フロントエンドチームが管理するapp of appsパターンの親リポジトリ path: kubernetes/overlays/[環境名] destination: server: https://kubernetes.default.svc namespace: argocd syncPolicy: automated: {} これにより、ArgoCD上で他チームと干渉する場所が木の間にマニフェストファイルが絞り込まれました。</description></item><item><title>Argo Rolloutsの利用</title><link>https://uyeong.github.io/nicolive-kubernetes-migration-handbook-2022/docs/ci/argo-rollouts/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://uyeong.github.io/nicolive-kubernetes-migration-handbook-2022/docs/ci/argo-rollouts/</guid><description>Argo Rolloutsの導入 # Argo Rolloutsとは # Argo RolloutsはKubernetes上にPodをデプロイする方法の選択肢を増やしてくれます。 Blue/Greenデプロイ、Canaryデプロイ、Progressive Deliveryなど。
とくにTraffic Managementを利用したデプロイ方法は非常に魅力的で、利用しない理由は見当たりませんでした。 ちょうどArgo Rolloutsがv1系が利用可能な状態で、移行時の検証と同時に必要な機能が使えることを確認できたため導入しました。
2021/05 v1.0.0 2021/10 v1.1.0 2022/03 v1.2.0 Istio + Argo Rollouts # Istio自体はすでに利用可能な状態にあったため、Traffic Managementを実施するLoadBalancerはIstioを利用しています。
Istio - Traffic Management 他と比較はできていませんが、IstioでTraffic Managementをすると、IstioのService Meshの恩恵をそのまま得られることができCanaryデプロイ時にTraffic Weightが変化していることが観測できるようになります。 なお、Istio Ingress Gatewayの設定でその他の機能についても紹介しています。
Canary Deployを実施する # RolloutのManifestは.spec.strategy以外の部分はDeploymentと同じです。
apiVersion: argoproj.io/v1alpha1 kind: Rollout metadata: name: my-app spec: strategy: canary: trafficRouting: istio: virtualService: name: my-app routes: - http-my-app-primary maxSurge: 33% canaryService: my-app-canary stableService: my-app-stable dynamicStableScale: true steps: - setCanaryScale: matchTrafficWeight: true - pause: duration: 60 - setWeight: 34 - setCanaryScale: matchTrafficWeight: true - pause: duration: 60 - setWeight: 67 - setCanaryScale: matchTrafficWeight: true - pause: duration: 60 - setWeight: 100 特徴的なのはcanaryServiceとstableService用に2つのService定義が必要になるところです。 Rolloutsに定義されたServiceは</description></item><item><title>Slack Botによる自動化</title><link>https://uyeong.github.io/nicolive-kubernetes-migration-handbook-2022/docs/ci/slack-bot/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://uyeong.github.io/nicolive-kubernetes-migration-handbook-2022/docs/ci/slack-bot/</guid><description>Slack Botによる自動化 # Argo CDによるGitOpsの実現は同時にGitOpsを開発者に強制します。 すなわち、バージョンアップのためのcommitを実施し、Pull Requestを投げ、マージする必要があります。 更新頻度の多いアプリケーションを抱えた場合、この作業が非常に長く開発者の体験を悪くします。
そこで、Slack Botサーバーを作成しSlackにメッセージを入力することで手続き的なタスクをサーバー側に実施するようにしました。
バージョンアップのシーケンス図 # シーケンス図を使って紹介します。 バージョンアップの手順はSlack上でBotに対して次のようなコマンドを投げることから始まります。
# server-aをバージョン2.0.0に変更する @bot update version:2.0.0 app:servive-a これを受け取ったbotサーバーは、メッセージの入力者を判別したり、コマンド(update version)をパースしたりします。コマンドに応じてGitHub APIをCallし、JSONで記述されたファイル(User Config)を書き換え、commitします。 その後Pull Requestを作成して、結果をユーザーに返します。
作成されたPull RequestをさらにSlackからマージします。
@bot merge pr:123 これをシーケンス図で書き起こすと次のようになります。
基本的な操作はすべてSlack上から実施が可能で、開発者がバージョンアップのためにリポジトリをCloneして環境構築する必要はありません。
既存のアプリケーションのCIとKubernetes Manifestのリポジトリの連携 # Slack Botによって自動化されたKubernetesのManifestリポジトリは既存のリリースフローとも結合が容易になります。
例えば、アプリケーションにバージョンアップのCIタスクがあった場合、次のバージョン情報をSlackのWebhookを利用して先程と同じようにメッセージをBotに対して送るだけで結合できます。
# 擬似コード message=&amp;#34;{\&amp;#34;text\&amp;#34;:\&amp;#34;@bot update version:${nextVersion}app:service-a\&amp;#34;}&amp;#34; curl -X POST -H &amp;#39;Content-type: application/json&amp;#39; --data $message https://hooks.slack.com/services/{your_id} 大抵のサーバーはcurlかそれに類するHTTP Clientを用意できるため、たった2行挿入するだけでデプロイの簡略化ができます。
Slack Botによってデプロイ作業を最小工数で終わらせる # バージョンアップのコマンドを紹介しましたが、他にも10個程度のコマンドがあります。
リリース準備用のコマンド 最新のリリース情報の取得 次に投入される予定のバージョン情報の取得（差分） リリース用のチケット作成 リリースノート更新 など、リリースに関する一連の情報や作業が細かくできるようになっています。 特に、差分情報やリリースノートの作成などを自動で実施しているためリリースの影響範囲が単純明快になるため確認コストが最小限になっています。</description></item><item><title>BFFとIstio</title><link>https://uyeong.github.io/nicolive-kubernetes-migration-handbook-2022/docs/service-mesh/istio/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://uyeong.github.io/nicolive-kubernetes-migration-handbook-2022/docs/service-mesh/istio/</guid><description>BFFとIstio # Istio の利用 # Istio は既存のマイクロサービスに対して後付で導入することができ、 通信を可観測にしたり、負荷分散を実施したり、Proxyとしての機能を持っています。 Kubernetes 上で稼働するマイクロサービスの通信をよりプログラマブルに扱える機能を提供しています。
実際に触ってみるとistioが謳っているこれらの機能は有用で、サービスメッシュはKubernetesを運用する上で必要不可欠であることを実感させられます。
さて、詳細な部分はドキュメントを読むのが望ましいですが、とっつきにくい部分もあるのでフロントエンドのエンジニアが使うと便利な機能を紹介しつつ Istio のコンポーネント紹介します。
IstioとEnvoyの関係 # まずはIstioとEnvoyの関係について知っておく必要があります。
Envoyはそれ自体がProxyであり、nginxやApacheなどのL7 LBと似たような機能を提供しています。 大きな違いとして、Envoy はテレメトリが標準で豊富だったり、APIによる構成変更が可能だったりプログラマブルにコントロールできる機能を豊富に持っています。 すなわち再起動をせずに構成変更が容易であり、Argo RolloutsのCanary Deployで紹介したように Traffic Weight を柔軟に変更することが可能になります。
IstioはこのEnvoyを利用して、Kubernetes上で稼働するマイクロサービス間の通信を観測するために Control Plane から各 Pod に Sidecar として注入します。 Istioから提供されているEnvoyのDocker Imageはistio-proxyという名前で提供されており、kubectl get pod [podname]などで構成を確認するとistio-proxyという名前を確認することができます。
Envoy単体では通常以下のようなYAMLを記述して起動時に読み込ませることでEnvoyの設定変更を実施します。
https://www.envoyproxy.io/docs/envoy/latest/configuration/overview/examples Istio の場合、Envoy はすでに起動された状態で存在しているため、既存の設定が存在しています。 そのため、この構成変更をしたい場合はEnvoyFilterを利用します。
https://istio.io/latest/docs/reference/config/networking/envoy-filter/ ただ普段書くような Traffic Management 用の設定は別のコンポーネントを利用して簡易に記述することができます。
Component 名 役割 Gateway 受け入れ可能なホスト名、ポート番号、プロトコルなどを記述する Virtual Service PATH単位のルーティングの設定が可能。Traffic Weight の指定、Header や Query Parameter による個別のルーティング先もここで指定する。 Service Entry Kubernetes クラスタから外部へのアクセス制限など。 その他（https://istio.</description></item><item><title>アクセスログ</title><link>https://uyeong.github.io/nicolive-kubernetes-migration-handbook-2022/docs/service-mesh/access-log/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://uyeong.github.io/nicolive-kubernetes-migration-handbook-2022/docs/service-mesh/access-log/</guid><description>アクセスログ # Webフロントエンドが管理するサーバーにおける最重要なシステムの一つはアクセスログです。 不正アクセスなどのセキュリティ的な側面や、会社の収益のツリー構造に関わる部分など多くの重要な情報をここから得られます。 ゆえにこの部分のシステムは信頼度が最も高い方法で実現する必要があります。
したがって移行前のアーキテクチャをなるべく踏襲しつつ、Ingress Gatewayに近いところに配置する必要がありました。 また、ログは既存のfluentdの収集と連携する必要がありました。
最終的に本番で稼働しているアーキテクチャは次のようになります。
Ingress Gatewayとアクセスログ周りのアーキテクチャ # 戦略としてはIngress Gatewayの前段にnginxを配置し、クラスター外からのアクセスを最初にnginxが受けるようにしました。nginxから出力されるアクセスログはsyslogでUnix Socketを経由してfluent-bitに転送しています。 fluent-bitはsyslogをINPUTとして既存のfluentdと結合するために出力先のディレクトリとログの書き出しをコントロールしています。
このアーキテクチャに至った経緯を紹介します。
アクセスログの出力にnginxを利用している理由 # 今回は移行が伴っているため、なるべく低コストで移行を安全に実施したい狙いがありました。 もともとnginxからログを出力していることもあり、その実績からそのまま流用する形を取りました。
また、envoyによるアクセスログの出力も考慮に入れましたが、Cookieなどに含まれる情報を出力するためにluaを書く必要があったり、そのパース用にスクリプト自体が保守するのが大変であるため断念しました。
fluent-bitで収集してfluentdに渡している理由 # fluentdは移行前からあるログ収集の手段です。 fluent-bitはfluentdのC言語実装で、fluent-bitも出力先をfluentdと同じ場所に向けることは可能です。 しかしながらこれも移行をスムーズに進めるために既存のfluentdの設定を頑張ってfluent-bitに移すことはしませんでした。
nginxからfluent-bitにUnix Socket経由でログを送信している理由 # 最初、fluent-bitをDaemonSetとして配置してIngress Gateway用のNodeに配置するようにしていました。 nginxのログをstdoutで出力し、/var/log/containers/[containerId].logに出力されるnginxのログをfluent-bitのtail INPUTを利用して収集していました。
しかしながら、高rps環境下でtailを利用するとfluent-bitのtailが突然止まる不具合に遭遇しました。 これはissueに起票されていますが、活発でないとしてBotによって2022/04/09クローズされました。
https://github.com/fluent/fluent-bit/issues/3947 挙動を見ているとどうやら/var/log/containersに出力されるログファイルのシンボリックリンク先である、 /var/log/pods/[pod-id]/0.logが.gzファイルにアーカイブされるときにファイルディスクリプタあたりが変更されそこでうまくfluent-bitが処理できていなさそうだということがなんとなくわかっています。 とはいえこれを修正するためにfluent-bitにPull Requestを送って、リリースされるまでの間ログが収集できないとなると移行スケジュールに問題が発生するため別の方法を考えました。
幸い、AWSのfluent-bitのトラブルシューティングがあったのでここを参考にしました。
https://github.com/aws/aws-for-fluent-bit/blob/mainline/troubleshooting/debugging.md Scalingの章に高スループットでfluent-bitを運用するための方法が紹介されており、そこに「DaemonSetモデルからSidecarモデルへ」と「ログファイルのTailからLog Streamingモデルへ」の変更が有効であることが記述されていました。
すぐにこれを採用し、最初に紹介したアーキテクチャへと変貌を遂げました
具体的な設定 # これら理由を踏まえた上で設定は次のようになります。
nginxの出力先の設定 # ログは取り扱いしやすいように一度JSONで出力しています。 syslogは/tmp/sidecar-nginx/sys-log.sockに対して出力しています。
log_format json_access_format escape=json &amp;#39;{ 中略 }&amp;#39; server { access_log syslog:server=unix:/tmp/sidecar-nginx/sys-log.</description></item><item><title>Istio Ingress Gatewayの設定</title><link>https://uyeong.github.io/nicolive-kubernetes-migration-handbook-2022/docs/service-mesh/traffic-management/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://uyeong.github.io/nicolive-kubernetes-migration-handbook-2022/docs/service-mesh/traffic-management/</guid><description>Istio Ingress Gatewayの設定 # Ingress Gatewayクラスター外部に対してクラスター内部のServiceに対するルーティングを公開します(Ingressとは何か)。 IstioもIngress Gatewayを提供しており、L7のルーティング設定を記述することができます。
Istio Ingress Gatewayの設定を変更するためにはいくつかのComponentを定義する必要があり、代表的なのはドキュメント(Istio / Ingress Gateways)で紹介されているGatewayとVirtualServiceになります。 nginxやApacheのようにconfファイルを起動時に読み込む形式と違い、istioがEnvoyに対してAPI経由で設定変更を動的に変更することになります。 そのため、どのistio-proxy(GatewayもしくはSidecarとして機能しているEnvoy)に対して設定を適用させるか記述する必要があります。
ここでは、以下の図中のIstio Ingress Gatewayに対して設定を変更します。
hostsでルーティングを分ける # 例えばPCとスマートフォン(SP)でルーティング先を分けたい場合があります。 これを実現するためにはまずはGatewayを宣言する必要があります。 ここではわかりやすいようにPCのルーティング先をpc.example.com、SPの行き先をsp.example.comとして定義します。
PC用Gateway
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 apiVersion: networking.istio.io/v1alpha3 kind: Gateway metadata: name: pc-example-com namespace: demo spec: selector: app.kubernetes.io/name: istio-ingressgateway app.kubernetes.io/part-of: istio servers: - port: number: 33000 name: http protocol: HTTP hosts: - pc.</description></item><item><title>Global RateLimit</title><link>https://uyeong.github.io/nicolive-kubernetes-migration-handbook-2022/docs/rate-limit/global-ratelimit/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://uyeong.github.io/nicolive-kubernetes-migration-handbook-2022/docs/rate-limit/global-ratelimit/</guid><description>Global RateLimit # Global Rate LimitはIngress Gatewayより後方側にいるPodに対するリクエストの流量制限を実施します。 すなわち、Kubernetesクラスターまではリクエストは到達します。 envoyproxy/ratelimitはこれを実現するためのリファレンス実装で、外部サービスとして後付で導入することが可能です。
Trafficがingress gatewayに到達した後の大雑把な流れは次のとおりです。
rate_limit_serviceで指定されたマイクロサービスにたいしてgrpcで問い合わせをします。 envoyratelimitはredis（memcacheも利用可）に格納したDescriptorに対するリクエスト数の計算を実施します。 ratelimit.go#L164 fixed_cache_impl.go#L39-L128 結果をingress gatewayに対してRateLimitResponseに乗せて返却 ingress gatewayはレスポンスを受けて429を返すかどうか決定する。 Global Ratelimitの設定 # envoyproxy/ratelimitを利用するには2つの設定が必要です。
Descriptorの設置 Descriptorに対するRate Limitの定義 DescriptorはEnvoy（istio-proxy）に対して定義することが可能で、Gatewayとして機能しているistio-proxyだけでなく、Sidecarとして搭載されているistio-proxyに対しても定義することが可能です。
DescriptorはActionによって条件が定義することができ、これをリファレンス実装されたratelimitのマイクロサービスで使用することにより、特定のPATHやheaderに対してratelimitを適用することができます。
具体的な例を示しましょう。
:path単位でRate Limitをかける # 例えば、/というパスに対してRate Limitを作りたい場合、まずDescriptorをGatewayのistio-proxyに対して作る必要があります。
apiVersion: networking.istio.io/v1alpha3 kind: EnvoyFilter metadata: name: ratelimit-actions spec: workloadSelector: labels: app: istio-ingressgateway configPatches: - applyTo: VIRTUAL_HOST match: context: GATEWAY routeConfiguration: vhost: name: &amp;#34;&amp;#34; route: action: ANY patch: operation: MERGE value: rate_limits: - actions: - request_headers: # HTTPの場合Request Headerの`:path`にURIが格納されている header_name: &amp;#34;:path&amp;#34; # &amp;#34;PATH&amp;#34;という名前でDescriptorを作成する descriptor_key: PATH ※ これ以降、rate_limitsより上層の定義は省略します。</description></item><item><title>Local RateLimit</title><link>https://uyeong.github.io/nicolive-kubernetes-migration-handbook-2022/docs/rate-limit/local-ratelimit/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://uyeong.github.io/nicolive-kubernetes-migration-handbook-2022/docs/rate-limit/local-ratelimit/</guid><description>Local RateLimit # Global RateLimitとの違い
Local RateLimitとGlobal RateLimitの違いは守るスコープの違いにあります。 Global RateLimitはUpstream側のシステムを守るため、RateLimitのマイクロサービス間でリクエスト数を共有するためのストア(redisなど)を外側に持っています。 それに対し、Local RateLimitはRateLimitを提供するProxyだけがリクエスト数を保持でいればよいためインメモリーで実装することができます。
Kubernetes上におけるLocal RateLimitの設置候補
Local RateLimitを実施する候補は2つあります。
istio-proxy（Envoy）のLocal Ratelimit機能を利用する nginxをistio-proxyとAppの間に立たせ、nginxのRateLimitを利用する envoy と nginx の Rate Limit アルゴリズムの違い # envoy と nginx では Rate Limit のアルゴリズムが異なります。 ゆえに、バースト性のあるトラフィックに対する制限が異なり、どちらからの乗り換えに対しても検証なしで乗り換えすることはできません。
Proxy Server Rate Limit Algorithm nginx Leaky Bucket envoy Token Bucket envoyとnginxの設定例 # 例えばmyappというアプリケーションに対して10 rpsの Rate Limit の制限をかけ、バースト時のリクエストは50 rpsまで受け付けるようにした場合次のように記述できます。</description></item><item><title>RateLimitで負荷の上昇を防げないパターン</title><link>https://uyeong.github.io/nicolive-kubernetes-migration-handbook-2022/docs/rate-limit/ratelimit-is-unless/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://uyeong.github.io/nicolive-kubernetes-migration-handbook-2022/docs/rate-limit/ratelimit-is-unless/</guid><description>RateLimitで負荷の上昇を防げないパターン # RateLimit を導入したからといって必ずしも負荷状態をバーストさせない状態を作れるわけではありません。 Global RateLimit として利用可能なenvoyproxy/ratelimitや、 Envoy 本体にある Local RateLimit、nginx の持つ RateLimit の実装を注意深く見ると、RateLimit の計算に利用するのはリクエストのみです。 すなわち、レスポンスが返ったことを確認してカウントアップしたリクエスト数を下げるわけではないのです。 これはつまり、RateLimit よりも後方のサーバーがコネクションをキューイングした場合、RateLimit で指定したリクエスト数より多くのリクエストを処理することが可能になります。
発生メカニズム # 簡略化したシーケンス図でまずは状況を説明します。図中には以下が登場します。
名称 役割 User ブラウザなどのクライアント Proxy Request に対する Rate Limit を適用 Server(Frontend) BFF Server と置き換えても問題ない。図中のHeavy TaskはServer Side Renderingと解釈するとよい。 Server(Backend) Server(Frontend)が少なくとも1つ以上はクリティカルに依存するサーバー RateLimitが効いているにも関わらずServer(Frontend)のCPU使用率が上昇する流れ
何らかの理由によってServer(Backend)のレスポンスが遅くなる場合が発生 このとき、Server(Frontend)からのリクエストは設定したtimeoutまでコネクションを維持し続ける RateLimitはRequestに対してのみ有効なため、Limitが効かない間はServer(Frontend)にリクエストを送信する Server(Backend)のレスポンスタイムが正常に戻ると図中の4のResponseが発生する すると、Server(Frontend)にキューイングされたリクエストHeavy Taskが定常よりも多く実行される その結果、Server(Frontend)のCPU使用率が上昇する 問題点と対策 # 基本的にどのマイクロサービスも、連携しているマイクロサービスにSLA(Service Level Agreements)を満たせない可能性がある前提で振る舞いを決める必要があります。</description></item><item><title>水平スケール</title><link>https://uyeong.github.io/nicolive-kubernetes-migration-handbook-2022/docs/scalability/horizontal-pod-autoscaler/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://uyeong.github.io/nicolive-kubernetes-migration-handbook-2022/docs/scalability/horizontal-pod-autoscaler/</guid><description>水平スケール # Kubernetesは監視しているCPU使用率などのMetricsをもとにPodの数を自動的にスケーリングさせる機構、Horizontal Pod Autoscalingを持っています。 metrics serverを利用するとCPU使用率やMemory使用量をベースに水平スケールを支援してくれます。
Horizontal Pod Autoscaler # Horizontal Pod Autoscaler（以下HPA）は観測されたMetricsを元に指定のPodのreplicasを増減させる仕組みです。 Manifestの書き方はシンプルで、autoscaling/v2beta2で記述すると次のようになります。
apiVersion: autoscaling/v2beta2 kind: HorizontalPodAutoscaler metadata: name: myapp spec: minReplicas: 10 maxReplicas: 20 scaleTargetRef: kind: Deployment # Argo Rolloutsを使用している場合は Rollout を指定する apiVersion: argoproj.io/v1alpha1 name: myapp metrics: - type: Resource resource: name: cpu target: type: Utilization averageUtilization: 80 これは探索されたPodのCPU使用率が80%を超えるようになった場合に、それを下回るようにPod数を増加させます。 逆に下回った場合はminReplicasまで戻るように働きます。
注意点として、</description></item><item><title>負荷試験</title><link>https://uyeong.github.io/nicolive-kubernetes-migration-handbook-2022/docs/performance/load-test/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://uyeong.github.io/nicolive-kubernetes-migration-handbook-2022/docs/performance/load-test/</guid><description>負荷試験 # 負荷試験の目的 # Docker SwarmからKubernetesに移行するにあたり、移行前のスペックを移行後に同等以上のスペックを発揮することを試験する必要があります。 したがって、アプリケーション自体の詳細な性能テストではなく、クラスターとして同等の性能が発揮できていることが大雑把でも確認できればよい、というのがここでのゴールとなります。
評価するためにはPrometheusやDataDog Agentなどから収集したデータをGrafanaやDataDog Dashboardで確認しつつ再現性を持った試験を実施する必要があります。
何を試験するか # 実際に試験して確認した内容を次の表にまとめました。
試験内容 目的 経路上の Proxy を最小台数にしたときに想定するrpsを処理ことができるか確かめる Connection Pool や TCP ESTABLISHED に余裕があるか確認する Runtime（nodejs）やライブラリの処理可能なrpsを計測する 同じ Runtime やライブラリを使用しているアプリケーションの CPU/MEM リソースの基準値を見積もる Pod をスケールアウトしたときの rps に対するリソースの変化を確認する Pod 数に対するリソース使用量と rps の関係を把握する 連続的にリクエストを投げることでほかサービスに影響がないか確認する 負荷試験の対象は挙動に問題ないが、同じ Gateway を使っている場合や同じマシンに乗っている他のサービスに影響がないことを確かめる 基本的に「性能限界」と「リソースの見積」のための試験になります。 これらの情報を元に、常設のreplicasの見積りや、Horizontal Pod AutoscalerのためのCPUのlimit設定、 共倒れを防ぐためのRate Limit設定を割り出していきます。
合わせてリソースの値をどうやって決めるかを確認してみてください。
試験方法 # 他のマイクロサービスと連携していないHTTPサーバーを用意する # Kubernetesの一連の動作検証も含め以下のようなサーバーを用意しておくと検証が捗ります。</description></item><item><title>モニタリング</title><link>https://uyeong.github.io/nicolive-kubernetes-migration-handbook-2022/docs/performance/monitoring/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://uyeong.github.io/nicolive-kubernetes-migration-handbook-2022/docs/performance/monitoring/</guid><description>モニタリング # 言わずもがな、サーバーを持ちサービスを運用する上でモニタリングは必須です。 収集したログや Metrics は不正アクセスや障害の検知、アラートの発報などサービスの運営をする上で必ず必要な情報です。
利用しているモニタリングツール # 今回利用しているモニタリングツールは以下の 2 つがあります。
Explorer DashBoard 1 Prometheus Grafana 2 DataDog Agent DataDog 2 つ存在する理由は、費用的な面とツールの精度を確認するための理由があります。
DataDog は本番環境で使う。一部の開発環境でも検証可能な状態で利用する。 上記の DataDog を使わない環境では Prometheus と Grafana で代用する 2つのツールでモニタリングの精度を比較する（本来は最低でも 3 つあったほうが良い） どちらも同じ Metrics を収集できるため単体での Observability の差に大きく違いはありません。 ただ DataLakeとしてDataDogがすでに基盤として存在しているためメインは DataDog に各種情報が集約されています。
BFF サーバーの何を観測するか # BFF サーバーにおいて観測する主要なものは以下の表にまとめました。 どれも時系列データとして記録されるため時間変化が分かる状態になっています
BFF サーバーとして主に観測しているのは次のようなメトリクスになります。
※ 略語</description></item><item><title>負荷分散</title><link>https://uyeong.github.io/nicolive-kubernetes-migration-handbook-2022/docs/performance/load-balancing/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://uyeong.github.io/nicolive-kubernetes-migration-handbook-2022/docs/performance/load-balancing/</guid><description>負荷対策 # nodeSelector # NodeはPodが配置されるVMや物理マシンですが、 配置されるPodの処理内容によって使用されるリソースが大きく変わることがあります。 具体的にはIngress Gatewayはクラスター内外のトラフィックを集中的に処理することが事前にわかっています。 また、Ingress Gatewayがなければアプリケーションにアクセスできないため、必ずリソースが枯渇しない状態にする必要があります。 そのため、Gatewayとしての役割以外を持つPodと別のNodeに配置されるようにすることで、Podが安定して稼働できるリソースの確保を実現します。
KubernetesはNodeに対してラベルを付与し、PodにnodeSelectorを付与することで指定のNodeに対してPodを配置することができます。 Nodeに付与されているlabelは以下のコマンドで確認することができます。
$ kubectl get nodes --show-labels # 簡単のため表示を省略 gateway01 Ready &amp;lt;none&amp;gt; 1d v1.21.12 node-role=gateway gateway02 Ready &amp;lt;none&amp;gt; 1d v1.21.12 node-role=gateway worker01 Ready &amp;lt;none&amp;gt; 1d v1.21.12 node-role=worker worker02 Ready &amp;lt;none&amp;gt; 1d v1.21.12 node-role=worker この場合、workerに対してPodを配置したい場合は次のように記述することができます。
1 2 3 4 5 6 7 8 9 10 11 apiVersion: apps/v1 kind: Deployment metadata: name: app namespace: demo spec: template: # 中略 spec: nodeSelector: node-role: worker Node上へのPodのスケジューリング | Kubernetes PodAntiAffinity # Podのスケジューリングはデフォルトのまま使用すると、Nodeに対する配置は明示的にコントロールされません。 つまり、あるアプリケーションを搭載したPodがNodeに偏らないようにしたいが、偏ってしまう（逆も然り）など発生します。 特にBFFサーバーはステートレスなサーバーであるため、分散配置されている方が望ましいでしょう。</description></item><item><title>通信経路の切り替え</title><link>https://uyeong.github.io/nicolive-kubernetes-migration-handbook-2022/docs/migrate-practice/migrate-docker-swarm-to-kubernetes/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://uyeong.github.io/nicolive-kubernetes-migration-handbook-2022/docs/migrate-practice/migrate-docker-swarm-to-kubernetes/</guid><description>通信経路の切り替え # 移行前の状態（Phase 1）から移行後の状態（Phase 2）までのステップは次のような経路で実施しました。
Phase 経路 Phase 1 Apache → nginx → Container Phase 2 Apache → istio-ingressgateway → App(Docker Swarm) Phase 3 Apache → istio-ingressgateway → App(Kubernetes) Apache による経路変更はパス単位（URI 単位）で実施できるため、流量が明らかに少ないパスを管理するマイクロサービスから移行を実施しました。
移行の流れ # 移行時の細かい手順は次のようになります。
ApacheのBalancerMemberを利用してからPhase 1からPhase 2に切り替え istio-ingressgatewayとKubernetes内のネットワーク系の状態を確認 負荷試験の結果と照らし合わせて Gatewayのリソース使用量などを見る Phase 3への切り替え前に、Virtual Serviceで特定のHeaderかQuery Parameterを利用して移行後のPodに対してアクセス。 Kubernetes内への疎通も確認できた後、istio-ingressgatewayのTraffic Weightを完全に切り替える rps がそこまで高くない BFF はこの手順を繰り返すことで移行を淡々とすすめることができました。 高rpsのBFFサーバーはこの手順でやるにはリスクが高いので、トラフィックのミラーリングを実施してGatewayと Kubernetes クラスター全体の状態を確認していきます。 アクセスログで紹介したようにPodにログ出力のためのnginxが含まれるため、二重計上されないためにNodePortをistio-proxyに向けたものをミラーリングのためのポートとして提供しています。 nginxのミラーリングによって高rpsの時間変化がDataDogに蓄積され、そこから対応表を用いてリソースの逆算を実施し、移行フェーズへステップを進めることができました。</description></item><item><title>アプリケーションの移行</title><link>https://uyeong.github.io/nicolive-kubernetes-migration-handbook-2022/docs/migrate-practice/application/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://uyeong.github.io/nicolive-kubernetes-migration-handbook-2022/docs/migrate-practice/application/</guid><description>アプリケーションの移行 # Kubernetes移行にあたりBFFサーバーで調整した内容を紹介します。
Graceful Shutdown # プロセス終了命令(SIGTERM)などのシグナルを受け取ったときに、サーバーに残っているリクエストがレスポンスを返し終わってからプロセスを終了する仕組みです。 これはKubernetesでなくても実装すべき内容で、安全に処理を終わらせるために必要です。
expressでの実装例は次のとおりです。
import * as express from &amp;#34;express&amp;#34;; const app = express(); const httpServer = app.listen(process.env.PORT || 80); // SIGNALを受け取る process.on(&amp;#34;SIGTERM&amp;#34;, () =&amp;gt; { httpServer.close(); }); process.onでSIGNALを受け取ることができるため、そこでHTTP ServerをCloseするだけになります。 他にもWebSocket Serverを起動している場合もここでclose処理を実施すると安全に終了できます。
静的リソースのアップロード # 静的リソースはAmazon S3にアップロードされたファイルをCDN(CloudFront)から配信する形式を取っています。 そのため、S3にアップロードする処理が必要で、移行前はJenkinsでこれを実行していました。
静的リソースはこれまでJenkinsのタスクによってアップロードしていましたが、KubernetesのJobとして移行しました。
具体的には、アプリケーションのCIによってリリース用のnpmパッケージが作成され、Private Registryにアップロードされたり、 ものによってはGitHubのRelease Assetsにアップロードされたりしています。
Kubernetes上のJobは
npm packageにリリースする静的リソースをダウンロードし、 静的リソースのホスティングに本当に必要なファイルだけを抽出し、 S3にアップロード という処理を実施しています。
内部の処理は環境変数で処理できるように実装されており、npmパッケージとアップロード先のS3の保存先を選ぶことができます。 また、Argo CDのSync Waveと組み合わせて、 アプリケーションのDeploymentがApplyされるより前にこのJobを実行するように順序を決めることでクリティカルパスを形成することができます。 以下は静的リソースのアップロードJobの例です。
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 apiVersion: batch/v1 kind: Job metadata: name: static-resource-upload-job-v1.</description></item></channel></rss>